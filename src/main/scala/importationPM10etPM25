// 1. Importation brute des CSV (sans header)
val pm10_raw = spark.read
  .format("csv")
  .option("header", false)
  .option("sep", ",")
  .load("chemin/vers/pm10.csv")

val pm25_raw = spark.read
  .format("csv")
  .option("header", false)
  .option("sep", ",")
  .load("chemin/vers/pm25.csv")

// 2. Transformation au format “long” (unpivot)
// Pour PM10
val stationIndexes = 1 until pm10_raw.columns.length

val pm10_long = pm10_raw.flatMap { row =>
  val timestamp = row.getString(0)
  stationIndexes.map { i =>
    val value = row.getString(i)
    val code = pm10_raw.columns(i)
    if (value != null && value.nonEmpty) {
      (timestamp, code, value.toDouble)
    } else {
      null
    }
  }.filter(_ != null)
}.toDF("timestamp", "station_code", "pm10_value")

// Pour PM25
val stationIndexes25 = 1 until pm25_raw.columns.length

val pm25_long = pm25_raw.flatMap { row =>
  val timestamp = row.getString(0)
  stationIndexes25.map { i =>
    val value = row.getString(i)
    val code = pm25_raw.columns(i)
    if (value != null && value.nonEmpty) {
      (timestamp, code, value.toDouble)
    } else {
      null
    }
  }.filter(_ != null)
}.toDF("timestamp", "station_code", "pm25_value")



// Import du dataset principal
val stations_df = spark.read
  .format("csv")
  .option("header", true)
  .option("sep", ";")
  .load("chemin/vers/idf_data_clean.csv")

// Exemple de mapping "code station" -> "Nom de la Station"
// À remplir selon tes abréviations PM10/25 et Noms de station du csv principal
val mapping_seq = Seq(
  ("NOGENT", "La Hacquinière"),
  ("BOB", "Le Bourget"),
  ("CERGY", "Cergy Préfecture"),
  // ...
)
val mapping_df = mapping_seq.toDF("station_code", "Nom de la Station")

// Jointure PM10 enrichie
val pm10_enriched = pm10_long
  .join(mapping_df, "station_code")
  .join(stations_df, "Nom de la Station")

// Jointure PM25 enrichie
val pm25_enriched = pm25_long
  .join(mapping_df, "station_code")
  .join(stations_df, "Nom de la Station")
